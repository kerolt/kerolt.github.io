<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Kerolt's Blog</title><meta name=keywords content><meta name=description content="Posts - Kerolt's Blog"><meta name=author content="Kerolt"><link rel=canonical href=https://kerolt.github.io/posts/><meta name=google-site-verification content="NpIO0KEIJS0CPRzTzQCbYQdSRIyb0Lspx"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="2300A23B82DB579A2DEA6261191AD771"><link crossorigin=anonymous href=/assets/css/stylesheet.bac160dbfb451d3b958c7b16ede7310831652f1c7b9abec95d519b00de4cd6a5.css integrity="sha256-usFg2/tFHTuVjHsW7ecxCDFlLxx7mr7JXVGbAN5M1qU=" rel="preload stylesheet" as=style><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-web/style.css><link rel=icon href=https://kerolt.github.io/images/avatar/favicon.png><link rel=icon type=image/png sizes=16x16 href=https://kerolt.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://kerolt.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://kerolt.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://kerolt.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://kerolt.github.io/posts/index.xml><link rel=alternate hreflang=en href=https://kerolt.github.io/posts/><script src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://kerolt.github.io/posts/"><meta property="og:site_name" content="Kerolt's Blog"><meta property="og:title" content="Posts"><meta property="og:description" content="ExampleSite description"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://kerolt.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kerolt.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Posts"><meta name=twitter:description content="ExampleSite description"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://kerolt.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://kerolt.github.io/ accesskey=h title="Kerolt's Blog (Alt + H)">Kerolt's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kerolt.github.io/posts/ title=文章><span class=active>文章</span></a></li><li><a href=https://kerolt.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://kerolt.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://kerolt.github.io/archives/ title=归档><span>归档</span></a></li><li><a href=https://kerolt.github.io/about/ title=关于我><span>关于我</span></a></li><li><a href=https://kerolt.github.io/search/ title="🔍 (Alt + /)" accesskey=/><span>🔍</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://kerolt.github.io/>Home</a></div><h1>Posts
<a href=/posts/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>TC和XDP</h2></header><div class=entry-content><p>tc 和 XDP 都能对网络数据包进行处理，但它们位于 不同的网络协议栈层次，因此性能、能力和适用场景差别都很大：
项目 作用层级 处理方向 特点 XDP (eXpress Data Path) 驱动层（最早）：网络设备驱动入口处（L2 之前） 入站（Ingress） 极快，绕过内核协议栈，可直接丢包/转发 tc (Traffic Control) 内核网络栈层（L3/L4 之后） 入站 + 出站 通常用于带宽控制、QoS、流量整形等 Linux 网络包处理路径 下面这张图能清晰地看到 XDP 和 tc 各自处在什么位置：
+----------------------------------------+ | 用户空间 | | (应用层: Nginx, curl, ping, etc.) | +----------------------------------------+ ▲ │ send()/recv() │ +----------------------------------------+ | 内核网络协议栈 | |----------------------------------------| | L4 (TCP/UDP) | | L3 (IP 路由转发) | | L2 (Ethernet frame 处理) | +----------------------------------------+ ▲ ▲ │ │ tc ingress/qdisc tc egress/qdisc │ │ │ ▼ +----------------------------------------+ | XDP (eXpress Data Path) | | (位于网卡驱动中，最靠近硬件的钩子点) | +----------------------------------------+ ▲ │ NIC 驱动 / DMA 收包 处理路径细节对比 对比项 XDP tc (ingress/egress) 所在层级 NIC 驱动层（比内核协议栈还早） 内核网络栈（L3/L4 层之间） 钩子位置 驱动接收包 → DMA → XDP skb（socket buffer）进入或离开协议栈时 作用方向 仅支持 ingress（入站） 支持 ingress + egress 处理对象 原始数据包（frame） 封装后的 skb 性能 极高（可在百万 pps 级别） 中等（受内核调度和 qdisc 影响） 典型用途 DDoS 防护、早期丢包、快速转发、内核旁路 QoS、流量整形、限速、包分类 可编程性 eBPF 程序（xdp 程序） eBPF 程序（cls_bpf） 返回动作 XDP_PASS、XDP_DROP、XDP_TX、XDP_REDIRECT TC_ACT_OK、TC_ACT_SHOT、TC_ACT_REDIRECT 使用接口 ip link set dev eth0 xdp obj prog.o tc filter add dev eth0 ... bpf obj prog.o 数据处理流程举例 XDP 流程（最早阶段） [网卡接收包] ↓ [XDP 程序执行] ├── XDP_DROP：直接丢包（不进入内核） ├── XDP_PASS：让包进入内核协议栈 ├── XDP_TX：直接从驱动回发 └── XDP_REDIRECT：转发到其他网卡或 AF_XDP socket 典型用途：
...</p></div><footer class=entry-footer><span title='2025-10-29 00:00:00 +0000 UTC'>2025-10-29</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;287 words&nbsp;·&nbsp;Kerolt</footer><a class=entry-link aria-label="post link to TC和XDP" href=https://kerolt.github.io/posts/ebpf/tc%E5%92%8Cxdp/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>eBPF中何时使用字节序转换函数</h2></header><div class=entry-content><p>在 eBPF 中，什么时候应该用 bpf_htons、bpf_htonl、bpf_ntohs、bpf_ntohl？
这些 bpf_* 函数是 eBPF 程序中用于字节序转换的辅助函数。它们的作用与标准的 C 库中的 htons、htonl、ntohs、ntohl 类似，但针对 BPF 环境进行了优化或封装。它们用于在主机字节序（Host Byte Order）和网络字节序（Network Byte Order）之间进行转换。
简而言之，当在 BPF 程序中处理网络协议头部（如 IP、TCP、UDP）中的多字节字段时，就需要使用这些函数。
网络协议标准（例如，IPv4、TCP、UDP）规定所有多字节数值（如端口号、IP 地址、校验和等）都必须以网络字节序（大端序，Big-Endian）传输。
Note bpf_ntohs (Network To Host Short) & bpf_ntohl (Network To Host Long)
...</p></div><footer class=entry-footer><span title='2025-10-23 00:00:00 +0000 UTC'>2025-10-23</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;119 words&nbsp;·&nbsp;Kerolt</footer><a class=entry-link aria-label="post link to eBPF中何时使用字节序转换函数" href=https://kerolt.github.io/posts/ebpf/ebpf%E4%B8%AD%E4%BD%95%E6%97%B6%E4%BD%BF%E7%94%A8%E5%AD%97%E8%8A%82%E5%BA%8F%E8%BD%AC%E6%8D%A2%E5%87%BD%E6%95%B0/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>eBPF增强Nginx负载均衡</h2></header><div class=entry-content><p>Nginx 负载均衡基准测试 / # wrk -c100 "http://172.17.0.5" Running 10s test @ http://172.17.0.5 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 12.31ms 12.66ms 84.49ms 82.31% Req/Sec 5.71k 4.96k 12.98k 63.00% 113583 requests in 10.04s, 17.87MB read Requests/sec: 11313.86 Transfer/sec: 1.78MB Latency（延迟）
Avg 12.31ms：平均每个请求的响应时间为 12.31 毫秒 Stdev 12.66ms：标准差说明响应时间波动较大 Max 84.49ms：最长请求花了 84.49 毫秒 82.31% +/- Stdev：82% 的请求延迟在 ±1 标准差范围内（说明大部分请求分布较广） Req/Sec（每秒请求数）
Avg 5.71k：平均每个线程每秒发出约 5710 个请求 Stdev 4.96k：标准差说明不同时间点吞吐波动较大 Max 12.98k：单个线程的最高瞬时请求速率为 12.98k/s 63.00% +/- Stdev：约 63% 的样本在这个范围内 接下来我们利用套接字 eBPF 程序优化
...</p></div><footer class=entry-footer><span title='2025-10-21 00:00:00 +0000 UTC'>2025-10-21</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;535 words&nbsp;·&nbsp;Kerolt</footer><a class=entry-link aria-label="post link to eBPF增强Nginx负载均衡" href=https://kerolt.github.io/posts/ebpf/ebpf%E5%A2%9E%E5%BC%BAnginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Vue3路由与Vite的base</h2></header><div class=entry-content><p>虽然我不是一个专门搞前端的，但也会写点点 Vue。最近实验室项目写完后需要部署一下，这里我就使用了 Docker Compose 来部署。由于前端项目有前台用户端访问和后台管理端两个，而老师申请的服务器只开了 80 端口，因此我就打算使用 nginx 来反向代理：
http://example.com 为前台 http://example.com/admin 为后台 ok，那我就用了一个 nginx 容器做网关，其 nginx.conf 如下：
server { listen 80; listen [::]:80; server_name _; # 后台管理 location /admin/ { proxy_pass http://frontend-admin; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; } # 后端接口 location /api { proxy_pass http://backend:8080/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; } # minio location /images/ { proxy_pass http://minio:9000/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; } # 前台用户 location / { proxy_pass http://frontend-user/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; } location = /admin { return 301 /admin/; } } docker compose up -d 后，用户端能访问并且接口没问题，但是一到管理端 http://xx.xx.xx.xx/admin，就会是白屏，我检查了一下，管理端页面的标签栏标题是正确的，也就是 nginx 反向代理没问题，获取的 index-xxx.js 和 index-yyy.css 也没问题，那就奇了个怪了。
...</p></div><footer class=entry-footer><span title='2025-10-16 00:00:00 +0000 UTC'>2025-10-16</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;179 words&nbsp;·&nbsp;Kerolt</footer><a class=entry-link aria-label="post link to Vue3路由与Vite的base" href=https://kerolt.github.io/posts/%E5%AD%A6%E4%B9%A0%E9%9A%8F%E7%AC%94/vue3%E8%B7%AF%E7%94%B1%E4%B8%8Evite%E7%9A%84base/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>国内安装Docker CE</h2></header><div class=entry-content><p>以下操作基于 Debian12
# 1. 添加阿里的 Docker 镜像仓库证书 curl -fsSL https://mirrors.aliyun.com/docker-ce/debian/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/aliyun-docker.gpg # 2. 添加仓库 echo \ "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/aliyun-docker.gpg] https://mirrors.aliyun.com/docker-ce/linux/debian \ $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null # 3. 安装 sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 安装完成后，通常我们要将自己加入 docker 用户组：
usermod -aG docker ${USER} 之后还需配置一下国内镜像（/etc/docker/daemon.json）：
{ "registry-mirrors": [ "https://dockerproxy.net", "https://hub-mirror.c.163.com", "https://mirror.ccs.tencentyun.com", "https://mirrors.aliyun.com" ] }</p></div><footer class=entry-footer><span title='2025-10-13 00:00:00 +0000 UTC'>2025-10-13</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;67 words&nbsp;·&nbsp;Kerolt</footer><a class=entry-link aria-label="post link to 国内安装Docker CE" href=https://kerolt.github.io/posts/%E5%AD%A6%E4%B9%A0%E9%9A%8F%E7%AC%94/%E5%9B%BD%E5%86%85%E5%AE%89%E8%A3%85docker-ce/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>股票问题II与状态机dp</h2></header><div class=entry-content><p>本篇文章思路来源于 @bilibili/灵茶山艾府
题目描述：https://leetcode.cn/problems/best-time-to-buy-and-sell-stock-ii
相对于买卖股票的最佳时机 I，该问题可以多次买入和卖出股票以获取最大利益
...</p></div><footer class=entry-footer><span title='2025-09-24 00:00:00 +0000 UTC'>2025-09-24</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;379 words&nbsp;·&nbsp;Kerolt</footer><a class=entry-link aria-label="post link to 股票问题II与状态机dp" href=https://kerolt.github.io/posts/%E7%AE%97%E6%B3%95/%E8%82%A1%E7%A5%A8%E9%97%AE%E9%A2%98ii%E4%B8%8E%E7%8A%B6%E6%80%81%E6%9C%BAdp/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Windows Terminal分屏快捷键</h2></header><div class=entry-content><p>左右分屏: 使用 Alt+Shift+= 或 Alt+Shift+- 快捷键。 上下分屏: 使用 Alt+Shift+= 或 Alt+Shift+- 快捷键。 取消分屏: 使用 Ctrl+Shift+w 快捷键。 关闭当前标签: 使用 Ctrl+Shift+w 快捷键。</p></div><footer class=entry-footer><span title='2025-09-18 00:00:00 +0000 UTC'>2025-09-18</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;20 words&nbsp;·&nbsp;Kerolt</footer><a class=entry-link aria-label="post link to Windows Terminal分屏快捷键" href=https://kerolt.github.io/posts/%E5%AD%A6%E4%B9%A0%E9%9A%8F%E7%AC%94/windows-terminal%E5%88%86%E5%B1%8F%E5%BF%AB%E6%8D%B7%E9%94%AE/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Linux NAPI机制知识点总结</h2></header><div class=entry-content><p>对 https://docs.kernel.org/networking/napi.html 的总结
NAPI (New API，但现已无特定含义) 是 Linux 内核中用于高效处理网络数据包的一种机制，旨在减少高负载下的中断开销。
其​目的​​是为了解决传统基于中断的包处理在高流量下的性能问题（“中断活锁”）。通过混合​​中断​​和​​轮询​​模式，在低负载时使用中断保证低延迟，在高负载时切换到轮询保证高吞吐量。
设备通过中断通知有新数据包 -> 内核调度对应的 NAPI 实例 -> 在软中断上下文（或内核线程）中轮询处理多个数据包 -> 处理完毕后再打开中断。
核心数据结构与 API ​​struct napi_struct​​：
核心数据结构，代表一个 NAPI 实例，保存其状态信息。 通常与一个中断或一个队列（RX/TX）相关联。 ​​控制 API (初始化和状态管理)​​：
netif_napi_add() / netif_napi_del(): 向系统添加/删除一个 NAPI 实例（通常附加到网络设备上）。 napi_enable() / napi_disable(): 启用/禁用 NAPI 实例。禁用状态下实例不会被调度，poll 方法不会被调用。​​注意​​：API 非幂等，错误调用顺序可能导致死锁或竞态。 ​​数据路径 API (调度与处理)​​：
napi_schedule(): ​​核心调度函数​​。通常在设备的中断处理程序中调用，通知内核有数据需要处理，并获取 NAPI 实例的所有权。 napi_schedule_irqoff(): napi_schedule() 的变体，用于已知在中断上下文中调用的情况，可优化中断屏蔽操作。 napi_complete_done(): ​​完成处理函数​​。当驱动程序的 poll 方法处理完所有事件后调用此函数，释放实例的所有权。​​警告​​：budget 为 0 时绝不能调用；若处理恰好用完 budget 且工作已完成，需谨慎返回 budget - 1 或等待下次调用。 驱动程序实现要点 ​​poll 方法​​：
驱动必须实现的回调函数，由内核调度执行实际的数据包处理工作。 ​​参数 budget​​：限制一次 poll 调用最多可处理的​​接收​​（RX）数据包数量（发送 TX 处理无此限制）。若返回值为 budget，表示还有工作未完成，内核会再次调度；若小于 budget，表示本轮处理已完成。 ​​中断屏蔽策略​​：
...</p></div><footer class=entry-footer><span title='2025-09-17 00:00:00 +0000 UTC'>2025-09-17</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;230 words&nbsp;·&nbsp;Kerolt</footer><a class=entry-link aria-label="post link to Linux NAPI机制知识点总结" href=https://kerolt.github.io/posts/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux-napi%E6%9C%BA%E5%88%B6%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>什么是云原生（自我解惑）</h2></header><div class=entry-content><p>云原生​​是一套以​​微服务、容器、动态编排（如 Kubernetes）、DevOps​​为核心，旨在构建和运行​​弹性、可靠、敏捷​​的云化应用的最佳实践集合。
理解它的关键在于思维的转变：​​从把云当作一台更便宜的虚拟主机，转变为把云当作一个可无限扩展、按需取用的计算能力平台，并以此为前提来设计和构建应用。​
什么是云原生？ ​​云原生​​ 是一种构建和运行应用程序的全新方法论，它充分利用了云计算的优势。
简单来说，​​云原生 = 云 + 原生​​。
​​云​​：指的是应用程序运行在云环境中，而不仅仅是托管在云服务器上。 ​​原生​​：意味着应用程序从设计、开发、部署到运维的整个生命周期，都是​​专门为云环境而设计和构建的​​，是“云上的原住民”。 它不是某一种具体的技术，而是一套​​技术体系、方法论和最佳实践的集合​​，其核心目标是构建和运行​​弹性扩展、韧性可靠、易于管理、可观测、松耦合的现代化应用​​。
如何通俗地理解云原生 我们可以用一个生动的比喻来理解：
​​传统应用 vs. 云原生应用​​
想象一下，你要运送货物。
​​传统应用（像“巨石应用”）​​：就像把所有的货物都塞进一个巨大的、不可分割的木箱里。这个木箱非常沉重，需要一辆巨大的卡车（一台强大的服务器）来运输。如果想扩大运力，你必须换一辆更大的卡车（升级服务器，​​纵向扩展​​），这个过程很慢，而且一旦卡车抛锚，所有货物都会受损。
​​对应现实​​：一个庞大的、所有功能都紧密耦合在一起的传统软件（如一个庞大的 ERP 系统），部署和维护都非常笨重。 ​​云原生应用（像“乐高应用”）​​：就像把货物分装在许多标准化的小集装箱（​​微服务​​）里。每个集装箱都可以被单独搬运、检查、替换。你可以根据需要轻松地增加或减少集装箱的数量（​​弹性伸缩​​），并且用许多辆小卡车（廉价的普通服务器）组成车队来运输。即使有几辆小卡车坏掉，也只会影响部分货物，整个运输系统不会瘫痪。
​​对应现实​​：一个应用被拆分成许多小的、独立的服务（如用户服务、订单服务、支付服务），它们可以独立开发、部署和扩展。 云原生的四大核心要素 要支撑上述的“乐高式”应用，需要一套强大的技术框架。云原生主要由以下四大核心技术要素构成：
​​微服务​​
​​是什么​​：将大型单体应用拆分为一组小的、松耦合的、可独立部署和升级的服务。 ​​好处​​：每个服务可以由不同的团队用不同的技术栈开发，更新速度快，容错性高。 ​​容器化​​
​​是什么​​：最代表性的技术是 ​​Docker​​。它将应用程序及其所有依赖项（库、环境配置等）打包成一个标准化的、轻量级的、可移植的“容器镜像”。这个容器在任何地方（开发、测试、生产环境）的运行效果都是一致的。 ​​好处​​：解决了“在我这运行得好好的，到你那就出问题”的环境一致性问题，是应用的标准交付件。 ​​动态编排​​
​​是什么​​：最代表性的技术是 ​​Kubernetes​​。当你有成千上万个容器需要管理时，Kubernetes 就像一位​​超级调度员和管家​​。它负责自动部署容器、故障恢复（容器挂了自动重启）、弹性伸缩（流量大了自动增加容器数量）、负载均衡等。 ​​好处​​：实现了应用的自动化和智能化运维，是云原生的操作系统。 ​​DevOps 和持续交付​​
​​是什么​​：​​DevOps​​ 是一种文化理念和实践，它打通了开发（Development）和运维（Operations）团队，通过高度自动化工具链（如 CI/CD），实现软件的频繁、可靠、快速的交付。 ​​好处​​：使得从代码提交到应用上线的过程可以完全自动化，极大地加快了迭代速度。 ​​简单总结一下四者的关系​​：
我们用 ​​DevOps​​ 的文化和 ​​CI/CD​​ 的工具，来自动化地开发、构建和测试​​微服务​​，并将其打包成​​容器​​，最后交给 ​​Kubernetes​​ 这个编排系统去动态地管理和运行。
为什么需要云原生？它的优势是什么？ 采用云原生架构能带来巨大的商业和技术价值：
​​弹性与可扩展性​​：应用可以根据流量压力自动缩扩容，轻松应对“双十一”等高峰场景，同时节省空闲时的资源成本。 ​​高韧性与故障隔离​​：单个服务的故障不会导致整个系统崩溃，系统具备自愈能力。 ​​快速迭代与交付​​：微服务和 DevOps 使得新功能可以独立、频繁、安全地发布，大大加快了市场响应速度。 ​​资源利用率高​​：容器非常轻量，可以在同一台机器上密集部署，节省硬件成本。 ​​可移植性​​：容器化的应用可以运行在任何云平台（公有云、私有云、混合云）上，避免被单一云厂商锁定。 云环境和托管在云服务器上有什么区别 特性 托管在云服务器上（租用办公室） 构建在云环境上（打造智能企业） ​​核心思想​​ ​​“换地方”​​ ​​“换活法”​​ ​​比喻​​ 你租用了一间云厂商的​​办公室（云服务器）​​，然后把自家机房里的​​旧家具、旧电脑（传统应用）​​ 原封不动地搬了进去。运维方式完全没变。 你利用云厂商提供的​​全套智能办公解决方案（云服务）​​：按需使用的会议室（计算资源）、自动化的物流系统（CI/CD）、可随意拼拆的工位（容器）、智能调度系统（Kubernetes）来​​重新组建一个高效、灵活的现代化公司（云原生应用）​​。 ​​弹性伸缩​​ ​​手动、缓慢​​。需要更多资源时，需要人工干预去升级服务器配置（​​纵向扩展​​），这通常需要停机。 ​​自动、即时​​。应用可根据流量压力，自动增加或减少计算资源（​​横向扩展​​），过程无缝，按实际使用量计费。 ​​韧性/可靠性​​ ​​依赖单机​​。如果托管你应用的这台云服务器宕机，你的服务就中断了，直到你手动将其恢复或迁移到另一台服务器。 ​​内置高可用​​。应用被设计为分布式、多实例运行。即使底层一台或多台服务器宕机，编排系统会自动在健康的服务器上重启应用实例，用户无感知。 ​​资源管理​​ ​​以服务器为中心​​。你需要关心每台服务器的 CPU、内存、磁盘使用率，并进行运维。 ​​以应用为中心​​。你只需声明“我的应用需要 2 核 4G”，云平台会自动调度和分配资源，你不再需要关心应用具体跑在哪台物理机上。 ​​成本模式​​ ​​为资源预留付费​​。你租了一台云服务器，无论你是否满负荷使用它，你都需要为它整个月的配置付费。 ​​为资源消耗付费​​。你只为应用程序实际消耗的 CPU 秒、内存 MB、网络流量付费。利用率极高，成本显著优化。 ​​技术栈​​ 传统架构，如：​​单体应用​​ + ​​服务器​​ + ​​SSH 运维​​。 云原生架构，如：​​微服务​​ + ​​容器​​ + ​​Kubernetes​​ + ​​DevOps​​。 ​​与云的关系​​ ​​租赁关系​​。你只是租用它的基础空间和硬件。 ​​共生关系​​。你的应用深度使用了云提供的数据库、消息队列、AI、大数据等​​托管服务​​，与应用紧密集成。</p></div><footer class=entry-footer><span title='2025-09-17 00:00:00 +0000 UTC'>2025-09-17</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;110 words&nbsp;·&nbsp;Kerolt</footer><a class=entry-link aria-label="post link to 什么是云原生（自我解惑）" href=https://kerolt.github.io/posts/k8s/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BA%91%E5%8E%9F%E7%94%9F%E8%87%AA%E6%88%91%E8%A7%A3%E6%83%91/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>【k8s】什么是Service</h2></header><div class=entry-content><p>在 Kubernetes（K8s）中，Service（服务） 是一个非常核心、关键的抽象概念。它的主要作用是：
✅ 为一组 Pod 提供稳定的网络访问入口（IP + Port），实现服务发现和负载均衡。
为什么需要 Service？ 在 Kubernetes 中：
Pod 是临时的、动态的 —— 它们随时可能被调度、重启、扩缩容，IP 会变 如果其他应用或用户直接访问 Pod IP，一旦 Pod 重建，连接就会失败 我们需要一个稳定的访问端点（Service），无论后端 Pod 如何变化 Service 的核心功能为：
功能 说明 服务发现 通过 Service 名称（在集群内 DNS 可解析）访问后端应用 负载均衡 自动将请求分发到后端多个 Pod 实例 解耦访问与实现 用户访问 Service，无需关心后端是哪些 Pod、IP 是多少 支持多种暴露方式 可在集群内访问、节点上暴露、或对外暴露公网访问 Service 如何工作？ 创建一个 Service，并指定“选择器（selector）”来匹配一组 Pod（如 app: my-app） Kubernetes 为 Service 分配一个集群内唯一的虚拟 IP（ClusterIP） kube-proxy 组件在每个节点上设置 iptables/IPVS 规则，实现流量转发和负载均衡 当请求发送到 Service 的 IP:Port，流量会被自动转发到后端健康的 Pod Service 的 4 种类型 1️⃣ ClusterIP（默认） 只在集群内部可访问 为 Service 分配一个集群内虚拟 IP 适用于微服务之间互相调用 spec: type: ClusterIP ports: - port: 80 targetPort: 8080 selector: app: my-app 2️⃣ NodePort 在每个节点上开放一个端口（默认 30000-32767） 外部用户可通过 http://&lt;NodeIP>:&lt;NodePort> 访问服务 适合开发、测试或没有 LoadBalancer 的环境 spec: type: NodePort ports: - port: 80 targetPort: 8080 nodePort: 30007 # 可选，不填则自动分配 selector: app: my-app 3️⃣ LoadBalancer 适用于云平台（AWS、GCP、Azure、阿里云等） 云平台会自动创建一个外部负载均衡器，并分配公网 IP 用户通过公网 IP 访问服务 最适合生产环境对外暴露服务 spec: type: LoadBalancer ports: - port: 80 targetPort: 8080 selector: app: my-app 在 Minikube 或本地环境，可以使用 minikube service &lt;service-name> 来模拟 LoadBalancer。
...</p></div><footer class=entry-footer><span title='2025-09-07 00:00:00 +0000 UTC'>2025-09-07</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;292 words&nbsp;·&nbsp;Kerolt</footer><a class=entry-link aria-label="post link to 【k8s】什么是Service" href=https://kerolt.github.io/posts/k8s/k8s%E4%BB%80%E4%B9%88%E6%98%AFservice/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://kerolt.github.io/posts/page/2/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://kerolt.github.io/>Kerolt's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>