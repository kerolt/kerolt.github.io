<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>eBPF增强Nginx负载均衡 | Kerolt's Blog</title><meta name=keywords content="eBPF,Nginx"><meta name=description content='Nginx 负载均衡基准测试
/ # wrk -c100 "http://172.17.0.5"
Running 10s test @ http://172.17.0.5
  2 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    12.31ms   12.66ms  84.49ms   82.31%
    Req/Sec     5.71k     4.96k   12.98k    63.00%
  113583 requests in 10.04s, 17.87MB read
Requests/sec:  11313.86
Transfer/sec:      1.78MB

Latency（延迟）

Avg 12.31ms：平均每个请求的响应时间为 12.31 毫秒
Stdev 12.66ms：标准差说明响应时间波动较大
Max 84.49ms：最长请求花了 84.49 毫秒
82.31% +/- Stdev：82% 的请求延迟在 ±1 标准差范围内（说明大部分请求分布较广）

Req/Sec（每秒请求数）

Avg 5.71k：平均每个线程每秒发出约 5710 个请求
Stdev 4.96k：标准差说明不同时间点吞吐波动较大
Max 12.98k：单个线程的最高瞬时请求速率为 12.98k/s
63.00% +/- Stdev：约 63% 的样本在这个范围内


接下来我们利用套接字 eBPF 程序优化'><meta name=author content="Kerolt"><link rel=canonical href=https://kerolt.github.io/posts/ebpf/ebpf%E5%A2%9E%E5%BC%BAnginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/><meta name=google-site-verification content="NpIO0KEIJS0CPRzTzQCbYQdSRIyb0Lspx"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="2300A23B82DB579A2DEA6261191AD771"><link crossorigin=anonymous href=/assets/css/stylesheet.bac160dbfb451d3b958c7b16ede7310831652f1c7b9abec95d519b00de4cd6a5.css integrity="sha256-usFg2/tFHTuVjHsW7ecxCDFlLxx7mr7JXVGbAN5M1qU=" rel="preload stylesheet" as=style><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-web/style.css><link rel=icon href=https://kerolt.github.io/images/avatar/favicon.png><link rel=icon type=image/png sizes=16x16 href=https://kerolt.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://kerolt.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://kerolt.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://kerolt.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://kerolt.github.io/posts/ebpf/ebpf%E5%A2%9E%E5%BC%BAnginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/><script src=https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css><script src=https://cdn.jsdelivr.net/gh/fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js></script><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://kerolt.github.io/posts/ebpf/ebpf%E5%A2%9E%E5%BC%BAnginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"><meta property="og:site_name" content="Kerolt's Blog"><meta property="og:title" content="eBPF增强Nginx负载均衡"><meta property="og:description" content='Nginx 负载均衡基准测试 / # wrk -c100 "http://172.17.0.5" Running 10s test @ http://172.17.0.5 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 12.31ms 12.66ms 84.49ms 82.31% Req/Sec 5.71k 4.96k 12.98k 63.00% 113583 requests in 10.04s, 17.87MB read Requests/sec: 11313.86 Transfer/sec: 1.78MB Latency（延迟）
Avg 12.31ms：平均每个请求的响应时间为 12.31 毫秒 Stdev 12.66ms：标准差说明响应时间波动较大 Max 84.49ms：最长请求花了 84.49 毫秒 82.31% +/- Stdev：82% 的请求延迟在 ±1 标准差范围内（说明大部分请求分布较广） Req/Sec（每秒请求数）
Avg 5.71k：平均每个线程每秒发出约 5710 个请求 Stdev 4.96k：标准差说明不同时间点吞吐波动较大 Max 12.98k：单个线程的最高瞬时请求速率为 12.98k/s 63.00% +/- Stdev：约 63% 的样本在这个范围内 接下来我们利用套接字 eBPF 程序优化'><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-21T00:00:00+00:00"><meta property="article:modified_time" content="2025-10-21T00:00:00+00:00"><meta property="article:tag" content="EBPF"><meta property="article:tag" content="Nginx"><meta property="og:image" content="https://kerolt.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://kerolt.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="eBPF增强Nginx负载均衡"><meta name=twitter:description content='Nginx 负载均衡基准测试
/ # wrk -c100 "http://172.17.0.5"
Running 10s test @ http://172.17.0.5
  2 threads and 100 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    12.31ms   12.66ms  84.49ms   82.31%
    Req/Sec     5.71k     4.96k   12.98k    63.00%
  113583 requests in 10.04s, 17.87MB read
Requests/sec:  11313.86
Transfer/sec:      1.78MB

Latency（延迟）

Avg 12.31ms：平均每个请求的响应时间为 12.31 毫秒
Stdev 12.66ms：标准差说明响应时间波动较大
Max 84.49ms：最长请求花了 84.49 毫秒
82.31% +/- Stdev：82% 的请求延迟在 ±1 标准差范围内（说明大部分请求分布较广）

Req/Sec（每秒请求数）

Avg 5.71k：平均每个线程每秒发出约 5710 个请求
Stdev 4.96k：标准差说明不同时间点吞吐波动较大
Max 12.98k：单个线程的最高瞬时请求速率为 12.98k/s
63.00% +/- Stdev：约 63% 的样本在这个范围内


接下来我们利用套接字 eBPF 程序优化'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://kerolt.github.io/posts/"},{"@type":"ListItem","position":2,"name":"eBPF增强Nginx负载均衡","item":"https://kerolt.github.io/posts/ebpf/ebpf%E5%A2%9E%E5%BC%BAnginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"eBPF增强Nginx负载均衡","name":"eBPF增强Nginx负载均衡","description":"Nginx 负载均衡基准测试 / # wrk -c100 \u0026#34;http://172.17.0.5\u0026#34; Running 10s test @ http://172.17.0.5 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 12.31ms 12.66ms 84.49ms 82.31% Req/Sec 5.71k 4.96k 12.98k 63.00% 113583 requests in 10.04s, 17.87MB read Requests/sec: 11313.86 Transfer/sec: 1.78MB Latency（延迟）\nAvg 12.31ms：平均每个请求的响应时间为 12.31 毫秒 Stdev 12.66ms：标准差说明响应时间波动较大 Max 84.49ms：最长请求花了 84.49 毫秒 82.31% +/- Stdev：82% 的请求延迟在 ±1 标准差范围内（说明大部分请求分布较广） Req/Sec（每秒请求数）\nAvg 5.71k：平均每个线程每秒发出约 5710 个请求 Stdev 4.96k：标准差说明不同时间点吞吐波动较大 Max 12.98k：单个线程的最高瞬时请求速率为 12.98k/s 63.00% +/- Stdev：约 63% 的样本在这个范围内 接下来我们利用套接字 eBPF 程序优化\n","keywords":["eBPF","Nginx"],"articleBody":"Nginx 负载均衡基准测试 / # wrk -c100 \"http://172.17.0.5\" Running 10s test @ http://172.17.0.5 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 12.31ms 12.66ms 84.49ms 82.31% Req/Sec 5.71k 4.96k 12.98k 63.00% 113583 requests in 10.04s, 17.87MB read Requests/sec: 11313.86 Transfer/sec: 1.78MB Latency（延迟）\nAvg 12.31ms：平均每个请求的响应时间为 12.31 毫秒 Stdev 12.66ms：标准差说明响应时间波动较大 Max 84.49ms：最长请求花了 84.49 毫秒 82.31% +/- Stdev：82% 的请求延迟在 ±1 标准差范围内（说明大部分请求分布较广） Req/Sec（每秒请求数）\nAvg 5.71k：平均每个线程每秒发出约 5710 个请求 Stdev 4.96k：标准差说明不同时间点吞吐波动较大 Max 12.98k：单个线程的最高瞬时请求速率为 12.98k/s 63.00% +/- Stdev：约 63% 的样本在这个范围内 接下来我们利用套接字 eBPF 程序优化\n理解 Nginx 负载均衡的本质 Nginx 作为反向代理或负载均衡器，本质上是：\n从客户端接收请求（通过 accept() 建立 TCP 连接） 选择一个上游后端（upstream server） 在用户态发起一个新的 TCP 连接 到该后端 在两个 socket 之间中转数据（前端 \u003c-\u003e 后端） 关键点：Nginx 的负载均衡策略（如 round robin、ip_hash）在用户态决定；而实际的数据流是两个独立的 socket，中间的数据转发也在用户态进行（效率上有损）。\n当我们引入 eBPF（extended Berkeley Packet Filter） 时，目标往往是：\n把负载均衡逻辑下放到内核态 减少 Nginx 用户态转发开销 实现更快的流量分发（零拷贝、低延迟） 例如：\n用 eBPF 程序在 XDP 或 TC ingress hook 阶段直接选择后端； 或者使用 sockmap/sockhash 在内核中直接“转发”两个 socket 之间的数据。 使用 socket 映射转发网络包 socket 映射（socket map）是 eBPF 中的一种 BPF map 类型，它可以在内核中保存 socket 的引用（即 TCP 连接对象）， 从而允许 eBPF 程序直接操作和转发这些连接上的数据。它有两种形式：\n类型 名称 特点 BPF_MAP_TYPE_SOCKMAP sockmap 数组结构，按索引存 socket BPF_MAP_TYPE_SOCKHASH sockhash 哈希结构，可按 key 查找 socket 可以理解为：sockmap/sockhash = 一个“连接路由表”，存放 映射关系。 让 eBPF 程序在内核中知道“哪个 key 对应哪个 socket”。\n传统用户态转发的性能瓶颈，以 Nginx 为例：\nclient socket → Nginx 用户态 → upstream socket 数据流需要经过：\n2 次系统调用（recv + send） 2 次上下文切换（内核↔用户态） 1 次数据拷贝（内核缓冲区↔用户缓冲区） 当并发量很高（比如 wrk 10k QPS）时，这个过程就成为瓶颈。\n于是 Linux 引入了 socket 映射 + SK_MSG eBPF 程序可以直接在内核中完成转发：\n把所有连接（client 和 upstream）的 socket 引用注册进 sockmap； eBPF 程序在发送路径中（BPF_PROG_TYPE_SK_MSG）执行； 程序从 sockmap 中查找目标 socket； 内核直接把数据从一个 socket 发送到另一个 socket —— 零拷贝转发。 在 eBPF 优化体系中：\n控制面（Control Plane）：决定怎么转发（谁转发给谁） → 用户态（Nginx） 数据面（Data Plane）：实际执行转发 → 内核态（eBPF） socket 映射就是两者的“桥梁”：Nginx 负责把 socket 注册进 sockmap（告诉内核：client_fd 对应 upstream_fd），eBPF 程序负责从 sockmap 中查找目标并完成转发。\n这种模式的好处是：\neBPF 不需要自己维护连接； 用户态应用可以动态调整映射； 内核可以高性能地完成数据转发。 数据流简化示意图如下：\n传统 Nginx 转发 [Client Socket] ↓ recv() [用户态缓冲区] ↓ send() [Upstream Socket] eBPF + socket 映射优化后 [Client Socket] ↓ eBPF 程序 (SK_MSG) ↘︎ 查找 sockmap[key] ↓ [Upstream Socket] 整个转发在内核中完成，无需进入 Nginx 用户态。\n那优化的步骤如下：\n创建套接字映射； 在 BPF_PROG_TYPE_SOCK_OPS 类型的 eBPF 程序中，将新创建的套接字存入套接字映射中； 在流解析类的 eBPF 程序 (如 BPF_PROG_TYPE_SK_SKB 或 BPF_PROG_TYPE_SK_MSG ) 中，从套接字映射中提取套接字信息，并调用 BPF 辅助函数转发网络包; 加载并挂载 eBPF 程序到套接字事件。 socket 映射 这里使用 socket 映射（socket map）中的一种 BPF Map 类型：BPF_MAP_TYPE_SOCKHASH，它的值总是套接字文件描述符，而键则需要我们去定义。\ntypedef struct { __u32 source_ip; __u32 dest_ip; __u16 source_port; __u16 dest_port; __u32 protocol; } SockKey; struct { __uint(type, BPF_MAP_TYPE_SOCKHASH); __uint(key_size, sizeof(SockKey)); __uint(value_size, sizeof(int)); __uint(max_entries, 65535); __uint(map_flags, 0); } sock_ops_map SEC(\".maps\"); BPF_PROG_TYPE_SOCK_OPS 是 内核套接字操作回调类型的 eBPF 程序，它能在 TCP 连接的生命周期事件被触发时执行，包括：\nBPF_SOCK_OPS_PASSIVE_ESTABLISHED_CB：被动连接建立（如服务器 accept） BPF_SOCK_OPS_ACTIVE_ESTABLISHED_CB：主动连接建立（如客户端 connect） BPF_SOCK_OPS_TCP_CLOSE_CB：连接关闭 BPF_SOCK_OPS_STATE_CB：状态变化 也就是说，它可以跟踪 TCP socket 的整个生命周期，在连接建立/关闭时获取 socket 的五元组信息，并把 socket 存入 sockhash，从而让 内核态 eBPF 数据面程序（如 SK_MSG）可以直接高效地查找和转发 socket 数据。\n需要注意的是，BPF_PROG_TYPE_SOCK_OPS 程序跟踪了所有类型的套接字操作，我们只需要把新创建的套接字更新到映射中。\nSEC(\"sockops\") int bpf_sockmap(struct bpf_sock_ops* sockops) { // 只处理 IPv4 连接 if (sockops-\u003efamily != AF_INET) { return BPF_OK; } // 只处理已建立的连接 if (sockops-\u003eop != BPF_SOCK_OPS_PASSIVE_ESTABLISHED_CB \u0026\u0026 sockops-\u003eop != BPF_SOCK_OPS_ACTIVE_ESTABLISHED_CB) { return BPF_OK; } SockKey key = { .dest_ip = sockops-\u003eremote_ip4, .source_ip = sockops-\u003elocal_ip4, .dest_port = sockops-\u003eremote_port, .source_port = bpf_htonl(sockops-\u003elocal_port), .protocol = sockops-\u003efamily, }; bpf_sock_hash_update(sockops, \u0026sock_ops_map, \u0026key, BPF_NOEXIST); return BPF_OK; } 转发 socket 转发 socket 可以使用 BPF_PROG_TYPE_SK_MSG 类型的 eBPF 程序，它在内核中的定义是这样的：\nBPF_PROG_TYPE(BPF_PROG_TYPE_SK_MSG, sk_msg, struct sk_msg_md, struct sk_msg) 捕获 socket 中的发送数据包，并根据之前的 socket 映射进行转发：\nSEC(\"sk_msg\") int bpf_sock_redirect(struct sk_msg_md* msg) { SockKey key = { .source_ip = msg-\u003eremote_ip4, .dest_ip = msg-\u003elocal_ip4, .source_port = msg-\u003eremote_port, .dest_port = bpf_htonl(msg-\u003elocal_port), .protocol = msg-\u003efamily, }; bpf_msg_redirect_hash(msg, \u0026sock_ops_map, \u0026key, BPF_F_INGRESS); return SK_PASS; } 测试结果 / # wrk -c100 \"http://172.17.0.5\" Running 10s test @ http://172.17.0.5 2 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 7.88ms 6.22ms 55.43ms 68.53% Req/Sec 7.03k 4.99k 15.03k 69.00% 140073 requests in 10.05s, 22.04MB read Requests/sec: 13940.22 Transfer/sec: 2.19MB 吞吐提升 ≈ 23.2%。 平均延迟下降 ≈ 36.0%。 ","wordCount":"535","inLanguage":"en","image":"https://kerolt.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-10-21T00:00:00Z","dateModified":"2025-10-21T00:00:00Z","author":{"@type":"Person","name":"Kerolt"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://kerolt.github.io/posts/ebpf/ebpf%E5%A2%9E%E5%BC%BAnginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},"publisher":{"@type":"Organization","name":"Kerolt's Blog","logo":{"@type":"ImageObject","url":"https://kerolt.github.io/images/avatar/favicon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://kerolt.github.io/ accesskey=h title="Kerolt's Blog (Alt + H)">Kerolt's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kerolt.github.io/posts/ title=文章><span>文章</span></a></li><li><a href=https://kerolt.github.io/categories/ title=分类><span>分类</span></a></li><li><a href=https://kerolt.github.io/tags/ title=标签><span>标签</span></a></li><li><a href=https://kerolt.github.io/archives/ title=归档><span>归档</span></a></li><li><a href=https://kerolt.github.io/about/ title=关于我><span>关于我</span></a></li><li><a href=https://kerolt.github.io/search/ title="🔍 (Alt + /)" accesskey=/><span>🔍</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://kerolt.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://kerolt.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">eBPF增强Nginx负载均衡</h1><div class=post-meta><span title='2025-10-21 00:00:00 +0000 UTC'>2025-10-21</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;535 words&nbsp;·&nbsp;Kerolt</div><ul class=post-tags><li><a href=https://kerolt.github.io/tags/ebpf/>EBPF</a></li><li><a href=https://kerolt.github.io/tags/nginx/>Nginx</a></li></ul></header><aside id=toc-container class="toc-container wide"><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#nginx-%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1%e5%9f%ba%e5%87%86%e6%b5%8b%e8%af%95 aria-label="Nginx 负载均衡基准测试">Nginx 负载均衡基准测试</a></li><li><a href=#%e7%90%86%e8%a7%a3-nginx-%e8%b4%9f%e8%bd%bd%e5%9d%87%e8%a1%a1%e7%9a%84%e6%9c%ac%e8%b4%a8 aria-label="理解 Nginx 负载均衡的本质">理解 Nginx 负载均衡的本质</a></li><li><a href=#%e4%bd%bf%e7%94%a8-socket-%e6%98%a0%e5%b0%84%e8%bd%ac%e5%8f%91%e7%bd%91%e7%bb%9c%e5%8c%85 aria-label="使用 socket 映射转发网络包">使用 socket 映射转发网络包</a></li><li><a href=#socket-%e6%98%a0%e5%b0%84 aria-label="socket 映射">socket 映射</a></li><li><a href=#%e8%bd%ac%e5%8f%91-socket aria-label="转发 socket">转发 socket</a></li><li><a href=#%e6%b5%8b%e8%af%95%e7%bb%93%e6%9e%9c aria-label=测试结果>测试结果</a></li></ul></div></details></div></aside><script>let activeElement,elements;window.addEventListener("DOMContentLoaded",function(){checkTocPosition(),elements=document.querySelectorAll("h1[id],h2[id],h3[id],h4[id],h5[id],h6[id]"),activeElement=elements[0];const t=encodeURI(activeElement.getAttribute("id")).toLowerCase();document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active")},!1),window.addEventListener("resize",function(){checkTocPosition()},!1),window.addEventListener("scroll",()=>{activeElement=Array.from(elements).find(e=>{if(getOffsetTop(e)-window.pageYOffset>0&&getOffsetTop(e)-window.pageYOffset<window.innerHeight/2)return e})||activeElement,elements.forEach(e=>{const t=encodeURI(e.getAttribute("id")).toLowerCase();e===activeElement?document.querySelector(`.inner ul li a[href="#${t}"]`).classList.add("active"):document.querySelector(`.inner ul li a[href="#${t}"]`).classList.remove("active")})},!1);const main=parseInt(getComputedStyle(document.body).getPropertyValue("--article-width"),10),toc=parseInt(getComputedStyle(document.body).getPropertyValue("--toc-width"),10),gap=parseInt(getComputedStyle(document.body).getPropertyValue("--gap"),10);function checkTocPosition(){const e=document.body.scrollWidth;e-main-toc*2-gap*4>0?document.getElementById("toc-container").classList.add("wide"):document.getElementById("toc-container").classList.remove("wide")}function getOffsetTop(e){if(!e.getClientRects().length)return 0;let t=e.getBoundingClientRect(),n=e.ownerDocument.defaultView;return t.top+n.pageYOffset}</script><div class=post-content><h2 id=nginx-负载均衡基准测试>Nginx 负载均衡基准测试<a hidden class=anchor aria-hidden=true href=#nginx-负载均衡基准测试>#</a></h2><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>/ <span style=color:#09f;font-style:italic># wrk -c100 &#34;http://172.17.0.5&#34;</span>
</span></span><span style=display:flex><span>Running 10s <span style=color:#366>test</span> @ http://172.17.0.5
</span></span><span style=display:flex><span>  <span style=color:#f60>2</span> threads and <span style=color:#f60>100</span> connections
</span></span><span style=display:flex><span>  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span style=display:flex><span>    Latency    12.31ms   12.66ms  84.49ms   82.31%
</span></span><span style=display:flex><span>    Req/Sec     5.71k     4.96k   12.98k    63.00%
</span></span><span style=display:flex><span>  <span style=color:#f60>113583</span> requests in 10.04s, 17.87MB <span style=color:#366>read</span>
</span></span><span style=display:flex><span>Requests/sec:  11313.86
</span></span><span style=display:flex><span>Transfer/sec:      1.78MB
</span></span></code></pre></div><blockquote><p><strong>Latency（延迟）</strong></p><ul><li><strong>Avg 12.31ms</strong>：平均每个请求的响应时间为 <strong>12.31 毫秒</strong></li><li><strong>Stdev 12.66ms</strong>：标准差说明响应时间波动较大</li><li><strong>Max 84.49ms</strong>：最长请求花了 84.49 毫秒</li><li><strong>82.31% +/- Stdev</strong>：82% 的请求延迟在 ±1 标准差范围内（说明大部分请求分布较广）</li></ul><p><strong>Req/Sec（每秒请求数）</strong></p><ul><li><strong>Avg 5.71k</strong>：平均每个线程每秒发出约 <strong>5710 个请求</strong></li><li><strong>Stdev 4.96k</strong>：标准差说明不同时间点吞吐波动较大</li><li><strong>Max 12.98k</strong>：单个线程的最高瞬时请求速率为 12.98k/s</li><li><strong>63.00% +/- Stdev</strong>：约 63% 的样本在这个范围内</li></ul></blockquote><p>接下来我们利用套接字 eBPF 程序优化</p><h2 id=理解-nginx-负载均衡的本质>理解 Nginx 负载均衡的本质<a hidden class=anchor aria-hidden=true href=#理解-nginx-负载均衡的本质>#</a></h2><p>Nginx 作为反向代理或负载均衡器，本质上是：</p><ol><li><strong>从客户端接收请求</strong>（通过 <code>accept()</code> 建立 TCP 连接）</li><li><strong>选择一个上游后端（upstream server）</strong></li><li><strong>在用户态发起一个新的 TCP 连接</strong> 到该后端</li><li><strong>在两个 socket 之间中转数据</strong>（前端 &lt;-> 后端）</li></ol><p>关键点：Nginx 的负载均衡策略（如 round robin、ip_hash）在<strong>用户态</strong>决定；而实际的数据流是<strong>两个独立的 socket</strong>，中间的数据转发也在用户态进行（效率上有损）。</p><p>当我们引入 <strong>eBPF（extended Berkeley Packet Filter）</strong> 时，目标往往是：</p><ul><li><strong>把负载均衡逻辑下放到内核态</strong></li><li><strong>减少 Nginx 用户态转发开销</strong></li><li><strong>实现更快的流量分发（零拷贝、低延迟）</strong></li></ul><p>例如：</p><ul><li>用 eBPF 程序在 <strong>XDP</strong> 或 <strong>TC ingress hook</strong> 阶段直接选择后端；</li><li>或者使用 <strong>sockmap/sockhash</strong> 在内核中直接“转发”两个 socket 之间的数据。</li></ul><h2 id=使用-socket-映射转发网络包>使用 socket 映射转发网络包<a hidden class=anchor aria-hidden=true href=#使用-socket-映射转发网络包>#</a></h2><p><strong>socket 映射</strong>（socket map）是 eBPF 中的一种 <strong>BPF map</strong> 类型，它可以在内核中保存 <strong>socket 的引用</strong>（即 TCP 连接对象）， 从而允许 eBPF 程序直接操作和转发这些连接上的数据。它有两种形式：</p><table><thead><tr><th>类型</th><th>名称</th><th>特点</th></tr></thead><tbody><tr><td><code>BPF_MAP_TYPE_SOCKMAP</code></td><td>sockmap</td><td>数组结构，按索引存 socket</td></tr><tr><td><code>BPF_MAP_TYPE_SOCKHASH</code></td><td>sockhash</td><td>哈希结构，可按 key 查找 socket</td></tr></tbody></table><p>可以理解为：<strong>sockmap/sockhash = 一个“连接路由表”，存放 <code>&lt;key, socket></code> 映射关系。 让 eBPF 程序在内核中知道“哪个 key 对应哪个 socket”</strong>。</p><hr><p>传统用户态转发的性能瓶颈，以 Nginx 为例：</p><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>client socket → Nginx 用户态 → upstream socket
</span></span></code></pre></div><p>数据流需要经过：</p><ul><li>2 次系统调用（recv + send）</li><li>2 次上下文切换（内核↔用户态）</li><li>1 次数据拷贝（内核缓冲区↔用户缓冲区）</li></ul><p>当并发量很高（比如 wrk 10k QPS）时，这个过程就成为瓶颈。</p><p>于是 Linux 引入了 <strong>socket 映射 + SK_MSG eBPF 程序</strong>可以直接在内核中完成转发：</p><ol><li>把所有连接（client 和 upstream）的 socket 引用注册进 sockmap；</li><li>eBPF 程序在发送路径中（<code>BPF_PROG_TYPE_SK_MSG</code>）执行；</li><li>程序从 sockmap 中查找目标 socket；</li><li>内核直接把数据从一个 socket 发送到另一个 socket —— <strong>零拷贝转发</strong>。</li></ol><p>在 eBPF 优化体系中：</p><ul><li><strong>控制面（Control Plane）</strong>：决定怎么转发（谁转发给谁） → 用户态（Nginx）</li><li><strong>数据面（Data Plane）</strong>：实际执行转发 → 内核态（eBPF）</li></ul><p>socket 映射就是两者的“桥梁”：Nginx 负责把 socket 注册进 sockmap（告诉内核：client_fd 对应 upstream_fd），eBPF 程序负责从 sockmap 中查找目标并完成转发。</p><p>这种模式的好处是：</p><ul><li>eBPF 不需要自己维护连接；</li><li>用户态应用可以动态调整映射；</li><li>内核可以高性能地完成数据转发。</li></ul><hr><p>数据流简化示意图如下：</p><ol><li>传统 Nginx 转发</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[Client Socket]
</span></span><span style=display:flex><span>   ↓ recv()
</span></span><span style=display:flex><span>[用户态缓冲区]
</span></span><span style=display:flex><span>   ↓ send()
</span></span><span style=display:flex><span>[Upstream Socket]
</span></span></code></pre></div><ol start=2><li>eBPF + socket 映射优化后</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>[Client Socket]
</span></span><span style=display:flex><span>   ↓  eBPF 程序 (SK_MSG)
</span></span><span style=display:flex><span>   ↘︎ 查找 sockmap[key]
</span></span><span style=display:flex><span>       ↓
</span></span><span style=display:flex><span>   [Upstream Socket]
</span></span></code></pre></div><p>整个转发在内核中完成，无需进入 Nginx 用户态。</p><hr><p>那优化的步骤如下：</p><ol><li>创建套接字映射；</li><li>在 <code>BPF_PROG_TYPE_SOCK_OPS</code> 类型的 eBPF 程序中，将新创建的套接字存入套接字映射中；</li><li>在流解析类的 eBPF 程序 (如 <code>BPF_PROG_TYPE_SK_SKB</code> 或 <code>BPF_PROG_TYPE_SK_MSG</code> ) 中，从套接字映射中提取套接字信息，并调用 BPF 辅助函数转发网络包;</li><li>加载并挂载 eBPF 程序到套接字事件。</li></ol><h2 id=socket-映射>socket 映射<a hidden class=anchor aria-hidden=true href=#socket-映射>#</a></h2><p>这里使用 <strong>socket 映射</strong>（socket map）中的一种 BPF Map 类型：<code>BPF_MAP_TYPE_SOCKHASH</code>，它的值总是套接字文件描述符，而键则需要我们去定义。</p><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#069;font-weight:700>typedef</span> <span style=color:#069;font-weight:700>struct</span> {
</span></span><span style=display:flex><span>    __u32 source_ip;
</span></span><span style=display:flex><span>    __u32 dest_ip;
</span></span><span style=display:flex><span>    __u16 source_port;
</span></span><span style=display:flex><span>    __u16 dest_port;
</span></span><span style=display:flex><span>    __u32 protocol;
</span></span><span style=display:flex><span>} SockKey;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#069;font-weight:700>struct</span> {
</span></span><span style=display:flex><span>    <span style=color:#c0f>__uint</span>(type, BPF_MAP_TYPE_SOCKHASH);
</span></span><span style=display:flex><span>    <span style=color:#c0f>__uint</span>(key_size, <span style=color:#069;font-weight:700>sizeof</span>(SockKey));
</span></span><span style=display:flex><span>    <span style=color:#c0f>__uint</span>(value_size, <span style=color:#069;font-weight:700>sizeof</span>(<span style=color:#078;font-weight:700>int</span>));
</span></span><span style=display:flex><span>    <span style=color:#c0f>__uint</span>(max_entries, <span style=color:#f60>65535</span>);
</span></span><span style=display:flex><span>    <span style=color:#c0f>__uint</span>(map_flags, <span style=color:#f60>0</span>);
</span></span><span style=display:flex><span>} sock_ops_map <span style=color:#c0f>SEC</span>(<span style=color:#c30>&#34;.maps&#34;</span>);
</span></span></code></pre></div><p><code>BPF_PROG_TYPE_SOCK_OPS</code> 是 <strong>内核套接字操作回调类型</strong>的 eBPF 程序，它能在 <strong>TCP 连接的生命周期事件</strong>被触发时执行，包括：</p><ul><li><code>BPF_SOCK_OPS_PASSIVE_ESTABLISHED_CB</code>：被动连接建立（如服务器 accept）</li><li><code>BPF_SOCK_OPS_ACTIVE_ESTABLISHED_CB</code>：主动连接建立（如客户端 connect）</li><li><code>BPF_SOCK_OPS_TCP_CLOSE_CB</code>：连接关闭</li><li><code>BPF_SOCK_OPS_STATE_CB</code>：状态变化</li></ul><p>也就是说，它可以跟踪 TCP socket 的整个生命周期，在<strong>连接建立/关闭时获取 socket 的五元组信息</strong>，并把 socket 存入 sockhash，从而让 <strong>内核态 eBPF 数据面程序（如 SK_MSG）可以直接高效地查找和转发 socket 数据</strong>。</p><p>需要注意的是，<code>BPF_PROG_TYPE_SOCK_OPS</code> 程序跟踪了所有类型的套接字操作，我们只需要把<strong>新创建</strong>的套接字更新到映射中。</p><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#c0f>SEC</span>(<span style=color:#c30>&#34;sockops&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#078;font-weight:700>int</span> <span style=color:#c0f>bpf_sockmap</span>(<span style=color:#069;font-weight:700>struct</span> bpf_sock_ops<span style=color:#555>*</span> sockops) {
</span></span><span style=display:flex><span>    <span style=color:#09f;font-style:italic>// 只处理 IPv4 连接
</span></span></span><span style=display:flex><span><span style=color:#09f;font-style:italic></span>    <span style=color:#069;font-weight:700>if</span> (sockops<span style=color:#555>-&gt;</span>family <span style=color:#555>!=</span> AF_INET) {
</span></span><span style=display:flex><span>        <span style=color:#069;font-weight:700>return</span> BPF_OK;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#09f;font-style:italic>// 只处理已建立的连接
</span></span></span><span style=display:flex><span><span style=color:#09f;font-style:italic></span>    <span style=color:#069;font-weight:700>if</span> (sockops<span style=color:#555>-&gt;</span>op <span style=color:#555>!=</span> BPF_SOCK_OPS_PASSIVE_ESTABLISHED_CB <span style=color:#555>&amp;&amp;</span>
</span></span><span style=display:flex><span>        sockops<span style=color:#555>-&gt;</span>op <span style=color:#555>!=</span> BPF_SOCK_OPS_ACTIVE_ESTABLISHED_CB) {
</span></span><span style=display:flex><span>        <span style=color:#069;font-weight:700>return</span> BPF_OK;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    SockKey key <span style=color:#555>=</span> {
</span></span><span style=display:flex><span>        .dest_ip <span style=color:#555>=</span> sockops<span style=color:#555>-&gt;</span>remote_ip4,
</span></span><span style=display:flex><span>        .source_ip <span style=color:#555>=</span> sockops<span style=color:#555>-&gt;</span>local_ip4,
</span></span><span style=display:flex><span>        .dest_port <span style=color:#555>=</span> sockops<span style=color:#555>-&gt;</span>remote_port,
</span></span><span style=display:flex><span>        .source_port <span style=color:#555>=</span> <span style=color:#c0f>bpf_htonl</span>(sockops<span style=color:#555>-&gt;</span>local_port),
</span></span><span style=display:flex><span>        .protocol <span style=color:#555>=</span> sockops<span style=color:#555>-&gt;</span>family,
</span></span><span style=display:flex><span>    };
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#c0f>bpf_sock_hash_update</span>(sockops, <span style=color:#555>&amp;</span>sock_ops_map, <span style=color:#555>&amp;</span>key, BPF_NOEXIST);
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>return</span> BPF_OK;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=转发-socket>转发 socket<a hidden class=anchor aria-hidden=true href=#转发-socket>#</a></h2><p>转发 socket 可以使用 <code>BPF_PROG_TYPE_SK_MSG</code> 类型的 eBPF 程序，它在内核中的定义是这样的：</p><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#c0f>BPF_PROG_TYPE</span>(BPF_PROG_TYPE_SK_MSG, sk_msg,
</span></span><span style=display:flex><span>	      <span style=color:#069;font-weight:700>struct</span> sk_msg_md, <span style=color:#069;font-weight:700>struct</span> sk_msg)
</span></span></code></pre></div><p>捕获 socket 中的发送数据包，并根据之前的 socket 映射进行转发：</p><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#c0f>SEC</span>(<span style=color:#c30>&#34;sk_msg&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#078;font-weight:700>int</span> <span style=color:#c0f>bpf_sock_redirect</span>(<span style=color:#069;font-weight:700>struct</span> sk_msg_md<span style=color:#555>*</span> msg) {
</span></span><span style=display:flex><span>    SockKey key <span style=color:#555>=</span> {
</span></span><span style=display:flex><span>        .source_ip <span style=color:#555>=</span> msg<span style=color:#555>-&gt;</span>remote_ip4,
</span></span><span style=display:flex><span>        .dest_ip <span style=color:#555>=</span> msg<span style=color:#555>-&gt;</span>local_ip4,
</span></span><span style=display:flex><span>        .source_port <span style=color:#555>=</span> msg<span style=color:#555>-&gt;</span>remote_port,
</span></span><span style=display:flex><span>        .dest_port <span style=color:#555>=</span> <span style=color:#c0f>bpf_htonl</span>(msg<span style=color:#555>-&gt;</span>local_port),
</span></span><span style=display:flex><span>        .protocol <span style=color:#555>=</span> msg<span style=color:#555>-&gt;</span>family,
</span></span><span style=display:flex><span>    };
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#c0f>bpf_msg_redirect_hash</span>(msg, <span style=color:#555>&amp;</span>sock_ops_map, <span style=color:#555>&amp;</span>key, BPF_F_INGRESS);
</span></span><span style=display:flex><span>    <span style=color:#069;font-weight:700>return</span> SK_PASS;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=测试结果>测试结果<a hidden class=anchor aria-hidden=true href=#测试结果>#</a></h2><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>/ <span style=color:#09f;font-style:italic># wrk -c100 &#34;http://172.17.0.5&#34;</span>
</span></span><span style=display:flex><span>Running 10s <span style=color:#366>test</span> @ http://172.17.0.5
</span></span><span style=display:flex><span>  <span style=color:#f60>2</span> threads and <span style=color:#f60>100</span> connections
</span></span><span style=display:flex><span>  Thread Stats   Avg      Stdev     Max   +/- Stdev
</span></span><span style=display:flex><span>    Latency     7.88ms    6.22ms  55.43ms   68.53%
</span></span><span style=display:flex><span>    Req/Sec     7.03k     4.99k   15.03k    69.00%
</span></span><span style=display:flex><span>  <span style=color:#f60>140073</span> requests in 10.05s, 22.04MB <span style=color:#366>read</span>
</span></span><span style=display:flex><span>Requests/sec:  13940.22
</span></span><span style=display:flex><span>Transfer/sec:      2.19MB
</span></span></code></pre></div><ul><li>吞吐提升 ≈ <strong>23.2%</strong>。</li><li>平均延迟下降 ≈ <strong>36.0%</strong>。</li></ul></div><footer class=post-footer><nav class=paginav><a class=prev href=https://kerolt.github.io/posts/ebpf/ebpf%E4%B8%AD%E4%BD%95%E6%97%B6%E4%BD%BF%E7%94%A8%E5%AD%97%E8%8A%82%E5%BA%8F%E8%BD%AC%E6%8D%A2%E5%87%BD%E6%95%B0/><span class=title>« Prev</span><br><span>eBPF中何时使用字节序转换函数</span>
</a><a class=next href=https://kerolt.github.io/posts/%E5%AD%A6%E4%B9%A0%E9%9A%8F%E7%AC%94/vue3%E8%B7%AF%E7%94%B1%E4%B8%8Evite%E7%9A%84base/><span class=title>Next »</span><br><span>Vue3路由与Vite的base</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://kerolt.github.io/>Kerolt's Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>